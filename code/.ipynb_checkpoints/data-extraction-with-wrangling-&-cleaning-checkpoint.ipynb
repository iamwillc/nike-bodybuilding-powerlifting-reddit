{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://imgur.com/3Ua9VYU.png\" style=\"float: left; margin: 18px; height: 75px\"> \n",
    "\n",
    "## *Data Extraction with Wrangling & Cleaning*\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushshift Reddit API\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returning dataframe with subreddit and body of the comment.\n",
    "#API only accepts maximum value of 500.\n",
    "#Status code of 200 means request has succeeded. \n",
    "#AutoModerator comments are removed as well as [removed] comments since they have no use in the model. #datacleaning\n",
    "\n",
    "def reddit_comment_getter(subreddit,num_posts):\n",
    "    '''\n",
    "    Accumulates subreddit comments from Pushshift Reddit API\n",
    "    returns a pandas dataframe of subreddit & body of comment.\n",
    "    \n",
    "    reddit_comment_getter(subreddit,num_posts)\n",
    "    \n",
    "    Parameters -\n",
    "    \n",
    "    subreddit: name of subreddit in string format('name_of_subreddit') \n",
    "    \n",
    "    num_posts: minimum total rows of data in integer format(#), also the number of results pulled each time\n",
    "    '''\n",
    "    url='https://api.pushshift.io/reddit/search/comment'\n",
    "    params={\n",
    "        'subreddit': subreddit,\n",
    "        'size': num_posts\n",
    "    }\n",
    "    res=requests.get(url,params)\n",
    "    if res.status_code != 200:\n",
    "        return f\"Error {res.status_code}: {subreddit} doesn't work! Try Again\"\n",
    "    else:\n",
    "        resframed=pd.DataFrame(res.json()['data'])\n",
    "        df1=resframed.query('author != \"AutoModerator\" & `body` != \"[removed]\"')[['subreddit','body','created_utc']]\n",
    "\n",
    "    while len(df1)<num_posts:\n",
    "        oldest=df1[['created_utc']].iloc[-1]\n",
    "        params={\n",
    "        'subreddit': subreddit,\n",
    "        'size': num_posts-len(df1),\n",
    "        'before': oldest\n",
    "    }\n",
    "        res=requests.get(url,params)\n",
    "        if res.status_code != 200:\n",
    "            return f\"Error {res.status_code}: {subreddit} doesn't work! Try Again\"\n",
    "        else:\n",
    "            resframed2=pd.DataFrame(res.json()['data'])\n",
    "            df2=resframed2.query('author != \"AutoModerator\" & `body` != \"[removed]\"')[['subreddit','body','created_utc']]\n",
    "            df1=df1.append(df2)\n",
    "        time.sleep(3) #prevents 429 error! prevents overloading the server with huge amounts requests per second! \n",
    "    return (df1.reset_index())[['subreddit','body']]\n",
    "\n",
    "\n",
    "#.query syntax knowledge obtained from:\n",
    "    #https://stackoverflow.com/questions/26535563/querying-for-nan-and-other-names-in-pandas/26535881#26535881\n",
    "    #https://stackoverflow.com/questions/40045545/pandas-query-string-where-column-name-contains-special-characters\n",
    "    #https://stackoverflow.com/questions/13611065/efficient-way-to-apply-multiple-filters-to-pandas-dataframe-or-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Subreddit Comments\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodybuilding=reddit_comment_getter('bodybuilding',1000)\n",
    "powerlifting=reddit_comment_getter('powerlifting',1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating the Two Subreddits\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([bodybuilding,powerlifting],ignore_index=True).to_csv('./dataset/bbandpl.csv',escapechar='\\r',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bodybuilding</td>\n",
       "      <td>Lmao so classic is basically open now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bodybuilding</td>\n",
       "      <td>No one had a coach up until late 90s. Seems li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bodybuilding</td>\n",
       "      <td>Let’s all agree with enough and some. 1st plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bodybuilding</td>\n",
       "      <td>58 now 59 at Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bodybuilding</td>\n",
       "      <td>Where is the cheapest iso100 fruity pebbles? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>powerlifting</td>\n",
       "      <td>Eddie without a suit hasnt ever pulled over 46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>powerlifting</td>\n",
       "      <td>I used it for a brief amount of time. I think ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>powerlifting</td>\n",
       "      <td>Go for it, especially if these sources are pee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>powerlifting</td>\n",
       "      <td>Is anyone using JuggernautAI for powerlifting?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>powerlifting</td>\n",
       "      <td>150kg deadlift done. On my profile, not able t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         subreddit                                               body\n",
       "0     bodybuilding              Lmao so classic is basically open now\n",
       "1     bodybuilding  No one had a coach up until late 90s. Seems li...\n",
       "2     bodybuilding  Let’s all agree with enough and some. 1st plac...\n",
       "3     bodybuilding                             58 now 59 at Christmas\n",
       "4     bodybuilding  Where is the cheapest iso100 fruity pebbles? I...\n",
       "...            ...                                                ...\n",
       "1995  powerlifting  Eddie without a suit hasnt ever pulled over 46...\n",
       "1996  powerlifting  I used it for a brief amount of time. I think ...\n",
       "1997  powerlifting  Go for it, especially if these sources are pee...\n",
       "1998  powerlifting  Is anyone using JuggernautAI for powerlifting?...\n",
       "1999  powerlifting  150kg deadlift done. On my profile, not able t...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking csv\n",
    "pd.read_csv('../dataset/bbandpl.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
